{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaL4","dataSources":[{"sourceId":86023,"databundleVersionId":11376393,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":228486641,"sourceType":"kernelVersion"},{"sourceId":33384,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":27950,"modelId":39561},{"sourceId":172510,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":146846,"modelId":169361},{"sourceId":242129,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":206829,"modelId":224053},{"sourceId":284463,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":243776,"modelId":224071}],"dockerImageVersionId":30840,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1915.293623,"end_time":"2024-12-14T00:30:49.092769","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-13T23:58:53.799146","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"255af715ce8746cdada24bd57410a109":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"394ecaf7716f4d258e338f875ae4c835":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f09de95b95f64817b8bdf28c7278a20d","placeholder":"​","style":"IPY_MODEL_bbd7a2e18f6d4a3a9642a3827b9ced38","value":""}},"41c7e147e597489b8791785b0472f4f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a26c2110bbc4546b8d2d74aa636bdf9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a3cde1f4e394b269d342d937829dd4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a26c2110bbc4546b8d2d74aa636bdf9","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_255af715ce8746cdada24bd57410a109","value":5}},"8ba53add104149c4ba88b4138fd4498e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e268c538e6a48979b263677cbdaf279":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ba53add104149c4ba88b4138fd4498e","placeholder":"​","style":"IPY_MODEL_41c7e147e597489b8791785b0472f4f0","value":"Loading safetensors checkpoint shards: 100% Completed | 5/5 [02:13&lt;00:00, 28.89s/it]\n"}},"9e605e9455c24c8cac0ea9521feb3016":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_394ecaf7716f4d258e338f875ae4c835","IPY_MODEL_6a3cde1f4e394b269d342d937829dd4f","IPY_MODEL_8e268c538e6a48979b263677cbdaf279"],"layout":"IPY_MODEL_c1e5f9f23809451d918b10f2a03658c2"}},"bbd7a2e18f6d4a3a9642a3827b9ced38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1e5f9f23809451d918b10f2a03658c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f09de95b95f64817b8bdf28c7278a20d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"TRITON_PTXAS_PATH\"] = \"/usr/local/cuda/bin/ptxas\"\nimport re\nimport time\nimport random\nimport warnings\nfrom collections import Counter\nimport numpy as np, pandas as pd, polars as pl\n\nimport torch\nimport vllm\nfrom vllm import LLM, SamplingParams\n\nimport kaggle_evaluation.aimo_2_inference_server\n\nwarnings.simplefilter('ignore')","metadata":{"papermill":{"duration":24.379545,"end_time":"2024-12-13T23:59:21.97668","exception":false,"start_time":"2024-12-13T23:58:57.597135","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:33:26.041805Z","iopub.execute_input":"2025-03-28T16:33:26.042124Z","iopub.status.idle":"2025-03-28T16:34:25.949016Z","shell.execute_reply.started":"2025-03-28T16:33:26.042104Z","shell.execute_reply":"2025-03-28T16:34:25.948309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = True\nseed_everything(seed=5)\n\nstart_time = time.time()\ncutoff_time = start_time + (4 * 60 + 50) * 60\ncutoff_times = [int(x) for x in np.linspace(cutoff_time, start_time + 60 * 60, 50 + 1)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:34:56.976119Z","iopub.execute_input":"2025-03-28T16:34:56.976430Z","iopub.status.idle":"2025-03-28T16:34:56.987870Z","shell.execute_reply.started":"2025-03-28T16:34:56.976404Z","shell.execute_reply":"2025-03-28T16:34:56.987225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if os.getenv('KAGGLE_KERNEL_RUN_TYPE') or os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    llm_model_pth = '/kaggle/input/m/shelterw/deepseek-r1/transformers/light-r1-7b-ds-awq/1'\nelse:\n    llm_model_pth = '/kaggle/input/m/shelterw/deepseek-r1/transformers/light-r1-7b-ds-awq/1'\n\nMAX_NUM_SEQS = 95\nMAX_MODEL_LEN = 31000\n\nllm = LLM(\n    llm_model_pth,\n    #dtype=\"half\",                 # The data type for the model weights and activations\n    max_num_seqs=MAX_NUM_SEQS,    # Maximum number of sequences per iteration. Default is 256\n    max_model_len=MAX_MODEL_LEN,  # Model context length\n    trust_remote_code=True,       # Trust remote code (e.g., from HuggingFace) when downloading the model and tokenizer\n    tensor_parallel_size=4,       # The number of GPUs to use for distributed execution with tensor parallelism\n    gpu_memory_utilization=0.95,  # The ratio (between 0 and 1) of GPU memory to reserve for the model\n    seed=2025,\n)\n\ntokenizer = llm.get_tokenizer()","metadata":{"_kg_hide-output":true,"papermill":{"duration":237.271485,"end_time":"2024-12-14T00:03:19.252851","exception":false,"start_time":"2024-12-13T23:59:21.981366","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:36:46.976275Z","iopub.execute_input":"2025-03-28T16:36:46.976576Z","iopub.status.idle":"2025-03-28T16:38:46.130870Z","shell.execute_reply.started":"2025-03-28T16:36:46.976553Z","shell.execute_reply":"2025-03-28T16:38:46.130057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#base_system_prompt = \"\"\"You are a helpful and harmless math assistant. You should learn transferable problem-solving strategies from the given \"Example\", rather than memorizing specific instances. Break this question into parts. Take quality time to Verify every case and condition in the intermediate step. Iterate over every value of n from the least to the highest value without any assumptions or generalizations. CRUCIAL: Your response MUST END with exactly one \\\\boxed{} containing the final answer after modulo 1000. Don't stop generating until you reach this \\\\boxed{} answer.\\n\\n\"\"\"\n\nTOPIC_PROMPTS = {\n    \"Number Theory\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Break this question down first. Carefully Analyze and follow the problem statement exactly . Avoid: (- mis-calculations, - overly rough approximations, -imprecise handling of the radical–axis relations, - misapplication of an alternate counting method that over‐counted by introducing unnecessary factors, - incorrect generalization of the sum‐of‐digits formula over the whole range). **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put possible answer within \\\\boxed{} after taking modulo 1000.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"You MUST IGNORE  theoretical reasoning. You MUST TAKE QUALITY TIME TO PERFORM A real-time exhaustive verification of ALL CASES using Sagemath or Sympy. **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put ALL possible answers within \\\\boxed{} after taking modulo 1000.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Don't solve, ONLY take time to verify all search cases to the 7th case then STOP QUICKLY. Summarize with verified steps. NOTE: There are other cases that meet the condition after the 7th case, but because of time constraints and computational limitations, stop at the 7th case and find a pattern that satisfies other cases. You MUST AVOID initial rough search that might hint at a potential candidate, a more rigorous and detailed analysis is needed. DON'T hypothesize. **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put ALL possible answers within \\\\boxed{} after taking modulo 1000.\"\n        }\n        \n    ],\n    \n    \"Geometry\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Break this question down first. Carefully Analyze and follow the problem statement exactly . Avoid: (- mis-calculations, - overly rough approximations, -imprecise handling of the radical–axis relations, - misapplication of an alternate counting method that over‐counted by introducing unnecessary factors, - incorrect generalization of the sum‐of‐digits formula over the whole range). **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put possible answer within \\\\boxed{} after taking modulo 1000.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Break this question down first. Analyze Verify  Conditions. Solve. No mis-calculations. No overly rough approximations. No imprecise handling of the radical–axis relations. Take modulo 1000 of final answer.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Break this question down first, then analyze and verify every condition and solve it. Construct geometric diagrams and apply geometric principles, Don't make any assumptions. Avoid miscalculations when applying Theorems, and overly rough approximations and an imprecise handling of the radical–axis relations. **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put possible answer within \\\\boxed{} after taking modulo 1000.\"\n        }\n    ],\n    \n    \"Combinatorics\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Break this question down first. Carefully Analyze and follow the problem statement exactly . Avoid: (- mis-calculations, - overly rough approximations, -imprecise handling of the radical–axis relations, - misapplication of an alternate counting method that over‐counted by introducing unnecessary factors, - incorrect generalization of the sum‐of‐digits formula over the whole range). **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put possible answer within \\\\boxed{} after taking modulo 1000.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"You must Take quality time to Verify every small case for optimal accuracy with Exhaustive CAS Checks without making any assumptions in the question you will receive. If you don't verify every small case accurately, don't solve anything else. There should be NO OVERSIGHT OR ASSUMPTION DUE TO GENERALIZATION. Summarize what you have done so far making sure every calculation is VERY ACCURATE!!! Complete the solution and arrive at the ONLY accurate answer after taking modulo 1000. Put your final answer within \\\\boxed{}.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Solve this question step by step. Recheck every critical step for optimal accuracy. Do not mis‐simplify any expression. Summarize what you have done so far. Complete the solution. Take modulo 1000 of final answer. **IMPORTANT**: Put your final answer within \\\\boxed{}.\"\n        }\n    ],\n    \n    \"Algebra/Modular Arithmetic\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Break this question down first. Carefully Analyze and follow the problem statement exactly . Avoid: (- mis-calculations, - overly rough approximations, -imprecise handling of the radical–axis relations, - misapplication of an alternate counting method that over‐counted by introducing unnecessary factors, - incorrect generalization of the sum‐of‐digits formula over the whole range). **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put possible answer within \\\\boxed{} after taking modulo 1000.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Solve this question step by step. Recheck every critical step for optimal accuracy. Do not mis‐simplify any expression. Summarize what you have done so far. Complete the solution. Take modulo 1000 of final answer. **IMPORTANT**: Put your final answer within \\\\boxed{}.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"You must Take quality time to Verify every small case for optimal accuracy with Exhaustive CAS Checks without making any assumptions in the question you will receive. If you don't verify every small case accurately, don't solve anything else. There should be NO OVERSIGHT OR ASSUMPTION DUE TO GENERALIZATION. Summarize what you have done so far making sure every calculation is VERY ACCURATE!!! Complete the solution and arrive at the ONLY accurate answer after taking modulo 1000. Put your final answer within \\\\boxed{}.\"\n        }\n        \n    ]\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\n\ndef detect_topic(question):\n    question = question.lower()\n    \n    topic_patterns = {\n        \"Number Theory\": {\n            \"keywords\": {\"gcd\", \"lcm\", \"mod\", \"divisible\", \"prime\", \"congruence\", \n                         \"remainder\", \"factor\", \"multiple\", \"coprime\", \"composite\",\n                         \"diophantine\", \"euclidean\", \"bezout\", \"chinese remainder\",\n                         \"greatest common divisors\", \"sum of digits\", \"digit sum\", \n                         \"s(n)\", \"base 10\", \"digits\"},\n            \"weight\": 1.2,\n            \"regex\": r\"mod(ulo)?\\s*\\d+|prime\\s*power|≡\\s*\\d+\\s*\\(mod|sum\\s+of\\s+digits\"\n        },\n        \"Combinatorics\": {\n            \"keywords\": {\"arrange\", \"combination\", \"permutation\", \"probability\", \n                        \"graph\", \"tree\", \"path\", \"subset\", \"binomial\", \"pigeonhole\",\n                        \"inclusion-exclusion\", \"recurrence\", \"generating function\"},\n            \"weight\": 1.1,\n            \"regex\": r\"\\d+\\s*ways|arrang(e|ing).* (not|never)\"\n        },\n        \"Geometry\": {\n            \"keywords\": {\"triangle\", \"circle\", \"coordinate\", \"volume\", \"area\", \n                        \"circumradius\", \"altitude\", \"hypotenuse\", \"parabola\", \n                        \"ellipse\", \"theorem\", \"bisector\", \"bisects\", \n                        \"circumcircle of triangle\", \"orthocenter\"},\n            \"weight\": 1.0,\n            \"regex\": r\"\\b(r|d)\\s*=\\s*\\d+|foot\\s+of\\s+perpendicular\"\n        }\n    }\n\n    special_cases = {\n        \"Number Theory\": [\n            r\"\\bs\\(n\\)\\b\",\n            r\"sum\\s+of\\s+digits\",\n            r\"base\\s+10\",\n            r\"\\d+day\",\n            r\"polynomial\\s+congruence\",\n            r\"exponential\\s+mod\",\n            r\"remainder\\s+when\\s+divided\"\n        ],\n        \"Geometry\": [\n            r\"circumradius\\s*=\\s*\\d+\",\n            r\"triangle.*side\\s+lengths\",\n            r\"volume\\s+of\\s+cylinder\"\n        ],\n        \"Combinatorics\": [\n            r\"at\\s+least\\s+\\d+\\s*heads\",\n            r\"probability\\s+of\\s+winning\",\n            r\"vertices\\s+and\\s+edges\"\n        ]\n    }\n\n    scores = {topic: 0 for topic in topic_patterns}\n    \n    # Base scoring\n    for topic, data in topic_patterns.items():\n        # Keyword matches\n        kw_matches = len([kw for kw in data[\"keywords\"] if kw in question])\n        scores[topic] += kw_matches * data[\"weight\"]\n        \n        # Regex matches\n        if \"regex\" in data:\n            scores[topic] += len(re.findall(data[\"regex\"], question)) * 2\n    \n    # Special case boosts\n    for topic, patterns in special_cases.items():\n        for pattern in patterns:\n            if re.search(pattern, question, re.IGNORECASE):\n                scores[topic] += 3\n    \n    # Priority tiebreaker\n    priority_order = [\n        \"Number Theory\",\n        \"Combinatorics\", \n        \"Geometry\"\n    ]\n    \n    max_score = max(scores.values())\n    candidates = [t for t, s in scores.items() if s == max_score]\n    \n    for topic in priority_order:\n        if topic in candidates:\n            return topic\n    \n    return \"Number Theory\"  # Fallback to highest priority","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_boxed_text(text):\n    pattern = r'\\\\boxed{([^}]*)}'\n    matches = re.findall(pattern, text)\n    if not matches:\n        return \"\"\n    for match in matches[::-1]:\n        if match != \"\":\n            return match\n    return \"\"\n\ndef batch_message_filter(list_of_messages) -> tuple[list[list[dict]], list[str]]:\n    extracted_answers = []\n    list_of_messages_to_keep = []\n    for messages in list_of_messages:\n        answer = extract_boxed_text(messages[-1]['content'])\n        if answer:\n            extracted_answers.append(answer)\n        else:\n            list_of_messages_to_keep.append(messages)\n    return list_of_messages_to_keep, extracted_answers\n\ndef select_answer(answers):\n    counter = Counter()\n    for answer in answers:\n        try:\n            if int(answer) == float(answer):\n                counter[int(answer)] += 1 + random.random() / 1_000\n        except:\n            pass\n    if not counter:\n        return 210\n    _, answer = sorted([(v,k) for k,v in counter.items()], reverse=True)[0]\n    return answer%1000","metadata":{"papermill":{"duration":1.614384,"end_time":"2024-12-14T00:03:20.92038","exception":false,"start_time":"2024-12-14T00:03:19.305996","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:38:46.132020Z","iopub.execute_input":"2025-03-28T16:38:46.132279Z","iopub.status.idle":"2025-03-28T16:38:46.141839Z","shell.execute_reply.started":"2025-03-28T16:38:46.132254Z","shell.execute_reply":"2025-03-28T16:38:46.141247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def batch_message_generate(list_of_messages) -> list[list[dict]]:\n    # Enforce single-sequence processing for iterative refinement\n    assert len(list_of_messages) == 1, \"Use sequential mode for iterative prompts\"\n    \n    # Dynamic token limits based on remaining time\n    max_tokens = MAX_MODEL_LEN\n    \n\n    # Configure sampling parameters\n    sampling_params = SamplingParams(\n        temperature=0.6,\n        top_p=0.95,\n        min_p=0.05,\n        skip_special_tokens=True,\n        max_tokens=max_tokens,\n        stop=[\"</think>\"],\n        seed=777,\n    )\n\n    # Convert message chain to prompt text\n    list_of_texts = [\n        tokenizer.apply_chat_template(\n            conversation=messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n        for messages in list_of_messages\n    ]\n\n    # Generate response using LLM\n    request_output = llm.generate(\n        prompts=list_of_texts,\n        sampling_params=sampling_params,\n    )\n\n    # Update message chain with generated response\n    updated_messages = []\n    for messages, single_request_output in zip(list_of_messages, request_output):\n        # Append assistant's response to message history\n        messages.append({\n            'role': 'assistant', \n            'content': single_request_output.outputs[0].text\n        })\n        \n        # Store token count for sorting (maintains compatibility)\n        updated_messages.append((\n            len(single_request_output.outputs[0].token_ids),\n            messages\n        ))\n\n    # Sort by generated response length (ascending)\n    updated_messages.sort(key=lambda x: x[0])\n    \n    # Return only the message chain (drop length metadata)\n    return [messages for _, messages in updated_messages]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#prompts = [#\"You must Take quality time to Verify every small cases upto the 7th value before assuming a pattern. There should be NO OVERSIGHT OR ASSUMPTION DUE TO GENERALIZATION. Summarize what you have done so far making sure every calculation is VERY ACCURATE!!! Complete the solution and arrive at the ONLY accurate answer after taking modulo 1000. Put your final answer within \\\\boxed{}.\",\n           #\"Solve this question step by step. Recheck every critical step for optimal accuracy. Do not mis‐simplify any expression. Summarize what you have done so far. Complete the solution. Take modulo 1000 of final answer. **IMPORTANT**: Put your final answer within \\\\boxed{}.\",\n           #\"Break this question down first. Carefully Analyze and follow the problem statement exactly . Avoid: (- mis-calculations, - overly rough approximations, -imprecise handling of the radical–axis relations, - misapplication of an alternate counting method that over‐counted by introducing unnecessary factors, - incorrect generalization of the sum‐of‐digits formula over the whole range). **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put possible answer within \\\\boxed{} after taking modulo 1000.\",\n          #\"You MUST IGNORE  theoretical reasoning. You MUST TAKE QUALITY TIME TO PERFORM A real-time exhaustive verification of ALL CASEs using Sagemath or Sympy. **IMPORTANT**: Arrive at early answers. Before using an alternative method, Put ALL the possible answers within \\\\boxed{} after taking modulo 1000.\"\n          #]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:39:56.158451Z","iopub.execute_input":"2025-03-28T16:39:56.158796Z","iopub.status.idle":"2025-03-28T16:39:56.162252Z","shell.execute_reply.started":"2025-03-28T16:39:56.158771Z","shell.execute_reply":"2025-03-28T16:39:56.161581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_for_question(question: str) -> int:\n    if time.time() > cutoff_time:\n        return 210\n    topic = detect_topic(question)\n    prompts = TOPIC_PROMPTS.get(topic, TOPIC_PROMPTS[\"Number Theory\"])\n    \n\n    question += \" When solving a problem, YOU MUST follow the problem statement exactly and avoid switching to alternate methods that introduce extra factors or over-counting.. YOU MUST put ALL the suspected answers in \\\\boxed{} before verifying further\"\n    \n    messages = [{\"role\": \"system\", \"content\": \"Explore different method for each prompt instruction\"}]\n    all_extracted_answers = []\n\n    for i in range(3):\n        # Append current prompt configuration\n        messages.append({\"role\": \"user\", \"content\": f\"{prompts[i % 3]}\\n\\n{question}\"})\n\n        # Generate and print response\n        messages = batch_message_generate([messages])[0]\n        \n        print(f\"\\n===== PROMPT {i+1} RESPONSE =====\")\n        print(f\"Prompt Config: {prompts[i][:100]}...\")  # Show first 100 chars of prompt\n        print(f\"Generated Response: {messages[-1]['content'][-500:]}...\")# Show last 500 chars of response\n        print(\"-\"*70)\n\n        # Extract and store answer\n        _, extracted = batch_message_filter([messages])\n        all_extracted_answers.extend(extracted)\n        print(f\"Extracted answers: {all_extracted_answers}\")\n    \n    \n        \n        # Reset context while keeping system prompt\n        messages = [messages[0]] + [messages[-1]]  # Carry final response forward if needed\n\n    answer = select_answer(all_extracted_answers)\n    print(f\"Answer: {answer}\")\n    return answer % 1000","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(id_: pl.DataFrame, question: pl.DataFrame) -> pl.DataFrame | pd.DataFrame:\n    id_ = id_.item(0)\n    print(\"------\")\n    print(id_)\n    question = question.item(0)\n    answer = predict_for_question(question)\n    print(question)\n    print(\"------\\n\\n\")\n    return pl.DataFrame({'id': id_, 'answer': answer})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv(\n    '/kaggle/input/ai-mathematical-olympiad-progress-prize-2/reference.csv'\n).drop('answer', axis=1).to_csv('reference.csv', index=False)","metadata":{"papermill":{"duration":0.070038,"end_time":"2024-12-14T00:03:21.108027","exception":false,"start_time":"2024-12-14T00:03:21.037989","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:40:02.438790Z","iopub.execute_input":"2025-03-28T16:40:02.439114Z","iopub.status.idle":"2025-03-28T16:40:02.476189Z","shell.execute_reply.started":"2025-03-28T16:40:02.439088Z","shell.execute_reply":"2025-03-28T16:40:02.475502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.aimo_2_inference_server.AIMO2InferenceServer(predict)\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n#            '/kaggle/input/ai-mathematical-olympiad-progress-prize-2/test.csv',\n            'reference.csv',\n        )\n    )","metadata":{"papermill":{"duration":1644.24778,"end_time":"2024-12-14T00:30:45.363503","exception":false,"start_time":"2024-12-14T00:03:21.115723","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:40:02.919682Z","iopub.execute_input":"2025-03-28T16:40:02.920004Z","execution_failed":"2025-03-28T16:49:33.651Z"}},"outputs":[],"execution_count":null}]}